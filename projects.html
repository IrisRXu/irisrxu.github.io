<!DOCTYPE html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
    <link rel="stylesheet" href="style.css"> <!-- Link to your CSS file -->

    <title>Projects</title>

</head>
<body>
    <header>
        <nav class = "navbar">
            <ul> <!--unordered list-->
                <li class="left"><a href="index.html"><i class="fa-solid fa-home"></i></a></li> <!--list item-->
                <li><a href="about.html">About</a></li>
                <li><a href="projects.html" class="active">Projects</a></li>
                <!--<li><a href="contact.html">Contact</a></li>-->
            </ul>
        </nav>
    </header>

    <main>
        <section>
            <h2>Bipedal Walking Robot</h2>
            <p><em>Robotics & Embodied Interaction Design</em><br><br>
            This work-in-progress project reflects my interest in the physical dimension of human-computer interaction. Starting from initial concept through design and CAD modeling, and eventually to assembly, simulation, and testing, I'm gaining hands-on experience with the full development lifecycle of an embodied interactive system. The project requires me to consider the physical form factor and computational requirements alongside design concepts. This experience particularly informs my interest in tangible interfaces with seamless digital and physical integration.
            </p>
            <em>CAD, 3D Printing, Python</em>
        </section>

        <section>
            <h2>PillowSense: Smart Fabric for Sleep Monitoring</h2>
            <p><em>Research at MobileX Lab, Columbia University</em><br>
                <em>Human-Centered Health Technology</em>
             <br><br>
            This research project shows my commitment to designing unobtrusive technology that augments human wellbeing. Working with Dr. Xia Zhou, Dr. Qijia Shao, Lisa DiSalvo, and Colman Leung, we developed a novel smart fabric system that unobtrusively records vital and posture data during sleep, with accuracies aligning with clinical requirements. By embedding sensors directly into everyday objects (pillowcases), we created a solution that seamlessly integrates into users' daily routines. <br><br>

            In this project, I performed literature review, fabricated, tested, and iteratively refined the hardware prototype, facilitated user studies with 20 participants, and presented results at the Undergraduate Research Symposium. <br><br>

            The project demonstrates my ability to learn quickly, critically evaluate existing solutions, and balance human needs with hardware constraints when designing personal health technologies. Through this work, I developed expertise in computational fabrics and physical interfaces, gaining valuable insights into designing ubiquitous technology for personal health. This experience strengthened my interdisciplinary approach to human-computer interaction, combining technical implementation with thoughtful consideration of how technology integrates into daily life.
            </p>
            <em>Fabrication, Arduino, PCB design</em>
        </section>

        <section>
            <h2>Emotions through Art</h2>
            <p><em>Digital Wellbeing & Cultural Connection</em><br><br>
                This web development project showcases my interest in designing digital experiences that support mental wellbeing through creative connections. I conceptualized and implemented an AI-powered interface that creates meaningful relationships between user emotional states and artistic expressions from the MET museum database. The project demonstrates my ability to rapidly prototype user experiences that foster emotional reflection and cultural appreciation. By thoughtfully designing the interaction between users, AI systems, and cultural artifacts, this work illustrates my approach to creating technology that enriches human experience rather than simply solving functional problems.
            </p>
            <em>Team: Lulu Wang, Millie Chen</em><br>
            <em>Python, API, HTML/CSS</em>
        </section>

        <section>
            <h2>Liquid Classification and Area Prediction</h2>
            <p><em>Deep Learning for Sensing & Interaction</em><br><br>
                Developed convolutional neural networks using TensorFlow to classify liquids 
                and predict areas based on raw sensor inputs from electrical impedance 
                tomography (EIT), achieving 98% validation accuracy.

                This deep learning project demonstrates my technical expertise in developing and fine-tuning machine learning models to interpret sensor inputs. The model achieves 98% validation accuracy in area prediction on raw electrical impedance tomography (EIT) inputs collected from an arm band. This work connects to my broader interest in creating responsive interfaces that intelligently interpret user interactions and environmental conditions. The techniques developed here have potential applications in creating more intuitive and adaptive user interfaces that respond to physical contexts.
            </p>
            <em>Python, Seaborn, Tensorflow</em>
        </section>

        <section>
            <h2>Plant Recovery Data Analysis</h2>
            <p><em>Environmental Data Analysis & Sustainability</em><br><br>
                This project uses statistical analysis with R as a tool for environmental understanding. From plant recovery data collected from Mount St.Helens after its volcanic eruption, I applied linear regression methods to understand vegetation resilience after disturbance.
            </p>
        </section>

    </main>

    <footer>
        <p>Sep 2024 Iris Xu</p>
    </footer>
</body>
</html>